package de.bachd.bigdata;

import org.apache.hadoop.io.Text;
import org.apache.tez.runtime.api.ProcessorContext;
import org.apache.tez.runtime.library.api.KeyValueReader;
import org.apache.tez.runtime.library.api.KeyValueWriter;
import org.apache.tez.runtime.library.processor.SimpleProcessor;

public class GroupByProcessor extends SimpleProcessor {

	public GroupByProcessor(ProcessorContext context) {
		super(context);
		// TODO Auto-generated constructor stub
	}

	@Override
	public void run() throws Exception {
		KeyValueReader kvReader = (KeyValueReader) getInputs().values().iterator().next().getReader();
		KeyValueWriter kvWriter = (KeyValueWriter) getOutputs().values().iterator().next().getWriter();
		while (kvReader.next()) {
			Tuple tuple = (Tuple) kvReader.getCurrentKey();
			// Testweise wird nach ArtNr und ArtName gruppiert
			String column1 = "artikel.ArtNr";
			String column2 = "artikel.ArtName";
			String group1 = tuple.getColumnStringMap().get(column1);
			String group2 = tuple.getColumnStringMap().get(column2);
			Text key = new Text(group1 + ", " + group2);
			kvWriter.write(key, tuple);
		}

	}

	@Override
	public void initialize() {
		System.out.println("Initialize GroupByProcessor");
	}

}
