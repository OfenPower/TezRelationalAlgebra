package de.bachd.bigdata;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.tez.client.TezClient;
import org.apache.tez.dag.api.DAG;
import org.apache.tez.dag.api.DataSinkDescriptor;
import org.apache.tez.dag.api.DataSourceDescriptor;
import org.apache.tez.dag.api.Edge;
import org.apache.tez.dag.api.ProcessorDescriptor;
import org.apache.tez.dag.api.TezConfiguration;
import org.apache.tez.dag.api.TezException;
import org.apache.tez.dag.api.Vertex;
import org.apache.tez.dag.api.VertexManagerPluginDescriptor;
import org.apache.tez.dag.api.client.DAGClient;
import org.apache.tez.dag.api.client.DAGStatus;
import org.apache.tez.dag.library.vertexmanager.ShuffleVertexManager;
import org.apache.tez.mapreduce.input.MRInput;
import org.apache.tez.mapreduce.output.MROutput;
import org.apache.tez.runtime.library.api.TezRuntimeConfiguration;
import org.apache.tez.runtime.library.conf.UnorderedKVEdgeConfig;

/**
 * Hello World!
 *
 */
public class App extends Configured implements Tool {

	private static final String DATAINPUT = "DataInput";
	private static final String SCHEMEINPUT = "SchemeInput";
	private static final String OUTPUT = "Output";
	private static final String V1 = "v1";
	private static final String V2 = "v2";

	@Override
	public int run(String[] args) throws Exception {
		// Tez lokal aufsetzen
		TezConfiguration tezConf = new TezConfiguration(getConf());
		tezConf.setBoolean(TezConfiguration.TEZ_LOCAL_MODE, true);
		tezConf.set("fs.default.name", "file:///");
		tezConf.setBoolean(TezRuntimeConfiguration.TEZ_RUNTIME_OPTIMIZE_LOCAL_FETCH, true);

		// TezClient starten
		TezClient tezClient = TezClient.create("TezClient", tezConf);
		tezClient.start();

		return runJob(args, tezConf, tezClient);
	}

	private int runJob(String[] args, TezConfiguration tezConf, TezClient tezClient) throws TezException, IOException {
		// Datasource
		DataSourceDescriptor dataSource1 = MRInput
				.createConfigBuilder(new Configuration(tezConf), TextInputFormat.class, "artikel.csv").build();
		DataSourceDescriptor dataSource2 = MRInput
				.createConfigBuilder(new Configuration(tezConf), TextInputFormat.class, "artikel.scheme").build();
		DataSinkDescriptor dataSink1 = MROutput
				.createConfigBuilder(new Configuration(tezConf), TextOutputFormat.class, "output.csv").build();

		// Knoten erzeugen
		Vertex v1 = Vertex.create(V1, ProcessorDescriptor.create(DataProcessor.class.getName()));
		v1.setVertexManagerPlugin(VertexManagerPluginDescriptor.create(ShuffleVertexManager.class.getName()));
		v1.addDataSource(DATAINPUT, dataSource1);
		Vertex v2 = Vertex.create(V2, ProcessorDescriptor.create(SchemeProcessor.class.getName()), 1);
		v2.addDataSink(OUTPUT, dataSink1);

		// Edge erzeugen
		UnorderedKVEdgeConfig e = UnorderedKVEdgeConfig.newBuilder(IntWritable.class.getName(), Text.class.getName())
				.setFromConfiguration(tezConf).build();
		Edge e1 = Edge.create(v1, v2, e.createDefaultBroadcastEdgeProperty());

		// Graph erzeugen und starten
		DAG dag = DAG.create("dag");
		dag.addVertex(v1).addVertex(v2).addEdge(e1);
		DAGClient dagClient = tezClient.submitDAG(dag);
		try {
			DAGStatus dagStatus;
			dagStatus = dagClient.waitForCompletionWithStatusUpdates(null);
			System.out.println("DAG diagnostics: " + dagStatus.getDiagnostics());
		} catch (InterruptedException e2) {
			e2.printStackTrace();
		}

		return 0;
	}

	public static void main(String[] args) throws Exception {
		ToolRunner.run(new Configuration(), new App(), args);
	}
}
