package de.bachd.bigdata.tez;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.Map;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.io.NullWritable;
import org.apache.tez.common.TezUtils;
import org.apache.tez.dag.api.UserPayload;
import org.apache.tez.runtime.api.ProcessorContext;
import org.apache.tez.runtime.library.api.KeyValueWriter;
import org.apache.tez.runtime.library.api.KeyValuesReader;
import org.apache.tez.runtime.library.processor.SimpleProcessor;

import com.google.common.base.Splitter;

import de.bachd.bigdata.aggregation.AggregationStrategy;
import de.bachd.bigdata.aggregation.CountStrategy;
import de.bachd.bigdata.aggregation.SumStrategy;
import de.bachd.bigdata.utils.Pair;

public class AggregationProcessor extends SimpleProcessor {

	private List<Pair<AggregationStrategy, String>> aggregateFunctions;

	public AggregationProcessor(ProcessorContext context) {
		super(context);
		aggregateFunctions = new ArrayList<>();
	}

	@Override
	public void run() throws Exception {
		KeyValuesReader kvsReader = (KeyValuesReader) getInputs().values().iterator().next().getReader();
		KeyValueWriter kvWriter = (KeyValueWriter) getOutputs().values().iterator().next().getWriter();
		while (kvsReader.next()) {
			// Text key = (Text) kvsReader.getCurrentKey();
			// Schema des Tupels speichern. Am Ende der Aggregation wird ein
			// neues Tupel mit diesem Schema plus neuer Spalten für
			// Aggregatfunktion (mit Ergebnis) erzeugt
			boolean schemeRead = false;
			List<String> relationNames = null;
			List<String> attributeNames = null;
			List<String> attributeDomains = null;
			List<String> attributeValues = null;
			// Alle gruppierten Tupel holen. Jedes dieser gruppierten Tuple
			// lässt sich durch den kvsReader nur einmal anfordern, daher muss
			// jedes angeforderte Tupel direkt durch alle Aggregatfunktionen
			// geschickt werden!
			for (Object obj : kvsReader.getCurrentValues()) {
				Tuple t = (Tuple) obj;
				if (!schemeRead) {
					relationNames = t.getRelationNames();
					attributeNames = t.getAttributeNames();
					attributeDomains = t.getAttributeDomains();
					attributeValues = t.getAttributeValues();
					schemeRead = true;
				}
				Map<String, String> valueMap = t.getColumnStringMap();
				// Jedes Tupel dieser Gruppe durch alle Aggregatfunktionen
				// schicken und jeweilige AttributeValues aggregieren!
				for (Pair<AggregationStrategy, String> pair : aggregateFunctions) {
					AggregationStrategy aggregate = pair.getLeft();
					aggregate.add(valueMap.get(pair.getRight()));
				}
			}

			// Ergebnis der verschiedenen Aggregationen holen.
			// Nachdem der Wert jedes Tupels der Gruppe mit der jeweiligen
			// AggregationStrategy aggregiert wurde, müssen die aggregierten
			// Werte für die nächste Gruppe wieder zurückgesetzt werden!
			for (Pair<AggregationStrategy, String> pair : aggregateFunctions) {
				AggregationStrategy aggregate = pair.getLeft();
				Object aggregatedValue = aggregate.getValue();
				// DEBUG: Aggregierter Wert anzeigen!
				// System.out.println(key + ": " +
				// aggregate.getAggregateFunctionName() + ": " +
				// aggregatedValue);

				// Aggregatfunktionen als zusätzliche Spalte einfügen:
				// AttributeName = "aggFunc(attribute)"
				// AttributeDomain = Rückgabetyp der Aggregatfunktion
				// AttributeValue = Aggregierter Wert
				attributeNames.add(aggregate.getAggregateFunctionName() + "(" + pair.getRight() + ")");
				attributeDomains.add(aggregate.getResultDomain());
				attributeValues.add("" + aggregatedValue);

				// Aggregierten Wert zurücksetzen, damit dieser Wert für die
				// neue Gruppe berechnet werden kann!
				aggregate.setNeutral();
			}

			// Ergebnistuple erzeugen.
			Tuple aggregatedTuple = new Tuple();
			aggregatedTuple.set(relationNames, attributeNames, attributeDomains, attributeValues);
			// DEBUG
			aggregatedTuple.printColumnValues();
			NullWritable nullValue = NullWritable.get();
			kvWriter.write(aggregatedTuple, nullValue); // Tuple an
														// ProjectionProcessor
														// rausschreiben
			System.out.println("---------------");

		}
	}

	@Override
	public void initialize() throws Exception {
		System.out.println("Initialize AggregationProcessor");
		UserPayload up = getContext().getUserPayload();
		Configuration conf = TezUtils.createConfFromUserPayload(up);
		String aggregateFunctions = conf.get("AggregateFunctions");
		System.out.println("Aggregate-Functions: " + aggregateFunctions);
		Iterable<String> aggregateFunctionsItr = Splitter.on(',').trimResults().omitEmptyStrings()
				.split(aggregateFunctions);
		for (String func : aggregateFunctionsItr) {
			System.out.println(func);
			Iterable<String> funcItr = Splitter.on('(').trimResults().omitEmptyStrings().split(func);
			Iterator<String> funcIterator = funcItr.iterator();
			while (funcIterator.hasNext()) {
				System.out.println(funcIterator.next());
			}

		}

		// Pair erzeugen: Left = aggregateFunction, Right = Attribut welches
		// aggregiert werden soll
		SumStrategy sumStrategy = new SumStrategy();
		CountStrategy countStrategy = new CountStrategy();
		Pair<AggregationStrategy, String> pair1 = new Pair<>(sumStrategy, "liegen.Bestand");
		Pair<AggregationStrategy, String> pair2 = new Pair<>(countStrategy, "liegen.LagerNr");
		this.aggregateFunctions.add(pair1);
		this.aggregateFunctions.add(pair2);
	}

}
